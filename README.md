# Computational Probability Learning Outcomes

## Enduring understanding

The following are the four ideas that I hope will persist with students after the minutia of the Poisson distribution has faded from memory.  Expand each section to see the associated learning outcomes and topics.

<details>
<summary>Probability is a framework for organizing beliefs; it is not a statement of what your beliefs should be.</summary>

| Learning outcomes | Topics |
|:------|:---|
| compare and contrast different definitions of probability, illustrating differences with simple examples | <ul><li>long-run proportion<li>personal beliefs<li>combination of beliefs and data |
| express the rules of probability verbally, mathematically, and computationally| <ul><li>AND, OR, complement, total probability<li>simulation error (relative and absolute) |
| illustrate the rules of probability with examples| |
| using long-run proportion definition of probability, derive the univariate rules of probability| |
| organize/express bivariate random variables in cross tables| |
| define joint, conditional, and marginal probabilities| |
| identify joint, conditional, and marginal probabilities in cross tables| |
| identify when a research question calls for a joint, conditional, or marginal probability| |
| describe the connection between conditional probabilities and prediction| |
| derive Bayes rule from cross tables| |
| apply Bayes rules to answer research questions| |
| determine if joint outcomes are independent| |
| calculate a measure of association between joint outcomes| |
| apply cross table framework to the special case of binary outcomes| <ul><li>Sensitivity<li>Specificity<li>Positive predictive value<li>Negative predictive value<li>Prevalence<li>Incidence |
| define/describe confounding variables | <ul><li>Simpson's paradox<li>DAGs<li>causal pathway |
| list approaches for avoiding confounding | <ul><li>stratification<li>randomization |
</details>

<details>
<summary>Probability models are a powerful framework for describing and simplifying real world phenomena as a means of answering research questions.</summary>

| Learning outcomes | Topics |
|:------|:---|
| list various data types| |
| match each data type with probability models that may describe it| <ul><li>Bernoulli<li>binomial<li>negative binomial<li>Poisson<li>Gaussian<li>gamma<li>mixture  |
| discuss the degree to which models describe the underlying data | |
| tease apart model fit and model utility| |
| express probability models both mathematically, computationally, and graphically| <ul><li>PMF/PDF<li>CMF/CDF<li>quantile function<li>histogram/eCDF |
| employ probability models (computationally and analytically) to answer research questions| |
| explain and implement different approaches for fitting probability models from data| <ul><li> Tuning <li>Method of Moments<li>Maximum likelihood<li>Bayesian posterior<li>kernel density estimation|
|visualize the uncertainty inherent in fitting probability models from data| <ul><li>sampling distribution<li>posterior distribution<li>bootstrap distribution |
| explore how to communicate uncertainty when constructing models and answering research questions| <ul><li>confidence intervals<li>support intervals<li>credible intervals<li>bootstrap intervals|
| propagate uncertainty in simulations | |
| explore the trade-offs of model complexity and generalizability| |
</details>

<details>
<summary>Probability is a framework for coherently updating beliefs based on new information and data.</summary>

| Learning outcomes | Topics |
|:------|:---|
| select prior distributions which reflect personal belief | <ul><li>informative vs weakly informative priors|
| implement bayesian updating | |
| manipulate the posterior distribution to answer research questions | |

</details>

<details>
<summary>Probability models can be expressed and applied mathematically and computationally.</summary>

| Learning outcomes | Topics |
|:------|:---|
| use probability models to build simulations of complex real world processes to answer research questions | |

</details>